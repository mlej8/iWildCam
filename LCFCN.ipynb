{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "835804a5-04cc-453d-8054-15dcfb09f04c",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4c68ad5-eda3-412a-ab92-2c6db2a655b7",
   "metadata": {},
   "source": [
    "We want to make all bounding boxes detected by MegaDetector into point-level annotations.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ddd98b86-87c9-45fb-845e-a545b6a456e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from config import *\n",
    "import pandas as pd\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cbc05efa-b728-45b2-ae05-99445f5f0889",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['info', 'images', 'detection_categories'])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(MEGATRON_BOUNDING_BOXES, encoding=\"utf-8\") as f:\n",
    "    megadetector_results = json.load(f)\n",
    "megadetector_results.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a20c2a1b-7763-4faf-8c76-24caa425d24a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataframe for bbox\n",
    "megadetector_results_df = pd.DataFrame(megadetector_results[\"images\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9f1c9e80-6492-46dc-9339-367d66f0bdf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# bounding boxes\n",
    "bb = [detection['bbox'] for detection in megadetector_results_df.iloc[175][\"detections\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2aeb8b18-91e9-416c-95e4-5c7eec6d156a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper method that converts a list of bounding boxes to a list of point-level annotations\n",
    "def bb_to_point(bb, im):\n",
    "    img_width, img_height = im.size[0], im.size[1]\n",
    "    return [(round(((2*box[0] + box[2])/2) * img_width),round(((2*box[1] + box[3])/2) * img_height)) for box in bb]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08eae2e1-526e-4e2b-ace2-6a2331391a97",
   "metadata": {},
   "source": [
    "# Binary count using LC-FCN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4c1366c3-009c-4a76-875c-5d47fd0950f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lcfcn import lcfcn, lcfcn_loss\n",
    "from PIL import Image\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f794032c-61a6-440e-8bae-154d20a30646",
   "metadata": {},
   "outputs": [],
   "source": [
    "# selecting an image with its associated bounding boxes\n",
    "data_index = 175\n",
    "\n",
    "# Load 100th image data. \n",
    "im = Image.open(TRAIN_DATA_DIR + \"/\" + megadetector_results_df.loc[data_index]['id'] + \".jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3a618b71-1114-425b-91f5-8e43835dc183",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = {}\n",
    "batch['images'] = lcfcn.transform_image(im)[None]\n",
    "batch['points'] = torch.zeros(batch['images'].shape[-2:])[None]\n",
    "point_list = points = bb_to_point(bb,im)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "be06e286-2a23-426c-b54f-ca11e0c55900",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(776, 351),\n",
       " (641, 348),\n",
       " (489, 329),\n",
       " (192, 321),\n",
       " (276, 310),\n",
       " (56, 311),\n",
       " (225, 312),\n",
       " (161, 315),\n",
       " (830, 249)]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "point_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07e28c72-50bf-40bf-87c6-a7620052bb9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 - loss: 13.169797897338867 {'mae': 104.0, 'game': 120.0}\n"
     ]
    }
   ],
   "source": [
    "# Train and Validate\n",
    "model = lcfcn.LCFCN(n_classes=1, lr=1e-5, device='cpu')\n",
    "\n",
    "for y,x in point_list:\n",
    "  batch['points'][:, y, x] = 1\n",
    "\n",
    "# train for several iterations\n",
    "for i in range(1000):\n",
    "    loss = model.train_on_batch(batch)\n",
    "    val_dict = model.val_on_batch(batch)\n",
    "    print(i, '- loss:', float(loss['train_loss']), val_dict)\n",
    "    if i % 10 == 0:\n",
    "        # visualize blobs and heatmap\n",
    "        model.vis_on_batch(batch, savedir_image='result.png')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "iWildcam-env",
   "language": "python",
   "name": "iwildcam-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}